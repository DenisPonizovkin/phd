% надо перенести на нашу оценку эффективности. То есть мы составляем 
% контент такого пользователя, что расстояние (то есть наша оценка эффективности)
% минимальна
В данной главе описана разработанная в рамках диссертационного исследования
математическая модель РС, основанная на теореии нечетких множеств.
В разработанной модели определены собственные методы решений задач и
обобщенная оценка качества решения.
Проведено теоретическое сравнение эффтиекности разработанной модели
и АКМ по критериям качества решения, вычислительной сложности алгоритмов и
стабильности.
Приведены свойства
разработанной оценки качества, показывающие, что разработанная оценка является
обобщающей оценкой эффективности по критерию качества, которая коррелирует с
суещствующими оценками.

\section{Предпосылки использования теории нечетких множеств}
РС --- гуманистические информационные РС \cite{fuzzy-ponomarev},
работающие с пользователями и их субъективными данными.
При работе с такими данными возникают ситуации неопределенности,
которые можно разделить на две категории:
\begin{enumerate}
\item отсутствие достаточно полного и достоверного знания о предметной области;
\item отсутствие возможности получить исчерпывающую информацию о пользователях
	и объектах.
\end{enumerate}

Существование первой категории неопределенности при работе с АКМ было
продемонстрировано в Главе 2, посвященной анализу АКМ. Было показано, что
эвристические утверждения этой предметной знаний не всегда выполняются, что
свидетельствует об отсутствии полных и достоверных знаний.
В том числе РС оперируют с такими нечеткими, неформальными понятиями, как
<<схож>>, <<обладать тенденцией>>, <<приблизительно равны>> , \lq
вкус>> , <<нравится>> т.п.,
которые точно и формально задать и описать довольно трудно.
Помимо эвристических утверждений, нечеткость присутствует в семантике значений
оценок близостей $\rho(u, i)$. Определить, к примеру, точную семантику между
значением оценки 0,6 и 0,65 довольно трудно, разница между ними размыта.
Вообще говоря, достаточно и полно определить поведение пользователя сложная задача, и
рассчитывать на полноту знаний в этой области не приходится.

Вторая ситуация описывается характерной для РС ситуацией,
которая заключается в разреженности матрицы исходных данных \cite{sparse1, sparse2, sparse3}.
Она определяется тем, что число известных оценок близости по отношение
к числу неизвестных крайне мало. Поэтому для некоторых пользователей
решение задач при помощи правил вывода АКМ невозможно. Или объекты, которые
оценило малое количество пользователей, не будут попадать в результирующее
множество при решении задач при помощи правил вывода АКМ.

Подобные ситуации неопределенности возникают также в экспертных
системах \cite{expert-systems} и в системах принятия решений \cite{set-theory}.
Можно найти некоторое пересечение между экспертными системами и
коллаборатиными РС \cite{cf-expert}. Одним из способов борьбы с
неопределенностью в экспертных системах и системах принятия решений
является применение теории нечетких множеств. Эта же теория была применен
в диссертационной работе для представления исходных данных.

\section{Введение в теорию нечетких множеств}
%ToDo ссылка на клас теорию и булеву логику
% ToDO:эффективным
Классическая теория множеств основана на булевой логике.
Принадлежность элемента некоторому множеству может принимать одно
из двух значений --- $\{0,1\}$ или ({\it истина} или {\it ложь}).
После появления нечетких множеств множества, представляемые при помощи классической теории
стали называть <<жесткими>>. Жесткость представления является источником
проблем при представлении нечетких
понятий при помощи классической теории. В приложении к РС жесткость
заключается в том, что классическая теория может рассматривать,
только два варианта развития событий, к примеру: выполняется ли отношение
близости между пользователем и объектом, или нет.
Такая семантика приемлема для задачи $topN$, так как для ее решения
и требуется определить множество объектов, между которыми и активным
пользователем выполняется отношение близости.
Однако для решения задачи прогнозирования РС должна уметь определять
оценку более гибко: к примеру, идеально, хорошо, удовлетворительно и т.п.

Рассмотрим применение теории нечетких множеств на примере. Предположим,
существует кинематографическая РС,
объектами которой являются фильмы. Характеристики объекта ---
это некоторая неформальная описательная информация.
Предположим, необходимо определить фильмы, которые можно было бы
описать экспертом как <<динамичные>> . В классической
теории множеств множество <<данимичных>>  фильмов $D$ можно было бы составить с
помощью некоторой характеристической функции $f : I \rightarrow D$.
Данную функцию можно было бы задать следующим образом:
\begin{equation*}
  f(i) =
  \begin{cases}
    1, &\text{если для фильма характерен жанр action}\\
    0, &\text{иначе}.
  \end{cases}
\end{equation*}
Представляя все множество <<динамичных>>  объектов $D$, интуитивно
кажется, что границы этого множества должны быть размыты, а
принадлежность элементов этому множеству может быть каким либо образом
ранжирована: можно говорить,
что один фильм динамичнее другого, или столь же динамичен. То есть все
множество $D$ можно упорядочить по свойству динамичности.
Таким образом, можно сказать про конкретный объект множества $D$, что он более
или менее типичен для этой области. К примеру,
фильмы могут обладать несколькими жанрами и могут существовать фильмы, которые
описываются исключительно жанром <<action>> ,
и тогда объект типичен элементу $D$. А могут обладать и нетипичными
жанрами для множества $D$, например
<<drama\rq , что придает драматический эффект и, тем самым, снижает его
динамичность и степень принадлежности множеству $D$.
Следовательно, можно задать некоторую функцию, с помощью которой
можно выразить степень принадлежность элемента к множеству. Пусть
на отрезке $[0,1]$ определена некоторая функция
$d: D \rightarrow [0,1]$, которая сопоставляет элементу $i \in D$ степень
его принадлежности множеству $D$. Если $d(i) = 1$, то можно утверждать, что
объект $D$ типичен для этого множества, если $d(i) = 0$, то можно утверждать, что
объект $D$ нетипичен для этого множества. Промежуточные значения между
$0$ и $1$ являются степенью принадлежности.
Множество $D$ называется нечетким подмножеством универсального множества
$I$, а функция $d$ --- характеристическая функция
принадлежности элементов универсального множества нечеткому подмножеству $D$.

\section{Представление данных в нечеткой модели}
\subsection{Контенты}
Нечеткие множества будем применять для описания информации об объектах и
пользователях системы.
Множество всех возможных характеристик будем называть
универсальным множеством. То есть во введенной терминологии и обозначениях
множество $X$ является универсальным множеством
характеристик пользователей,
а множество $Y$ --- универсальным множеством характеристик объектов.

\begin{defn}
				$c_X(u) = \{(x | w_U(u, x )) \}, w_U(u, x) \in [0,1]$ ---
				контент пользователя, $x \in X$. При этом множество $X$ не
				обязательно является множеством $I$, как в случае с АКМ, а,
				например, в качестве характеристик может выступать контекстная
				информация.
				$w_U(u, x)$ является
				характеристической функции принадлежности.
\end{defn}


\begin{defn}
				$c_Y(i) = \{(y | w_I(i, y )) \}, w_I(i, y) \in [0,1]$ ---
				контент объекта, $y \in Y$.
				$w_I(i, x)$ является
				характеристической функции принадлежности.

\end{defn}

\begin{defn}
				$c_X(u) = \varnothing$, если $w_U(u, x) \equiv 0$ ---
				пустой контент пользователя
\end{defn}

\begin{defn}
				$c_Y(i) = \varnothing$, если $w_I(i, y) \equiv 0$ ---
				пустой контент объекта

\end{defn}

\begin{defn}
	Если пересечение контентов объектов не является пустым контентом, то тогда
	такие элементы будем называть {\it сравнимыми}.
\end{defn}

\subsection{Основные операции над контентами}
Теория нечетких множеств позволяет определить такие операции над контентами,
как их пересечение, объединение и дополнение, так как контенты
являются нечеткими подмножествами. Данные операции будут применены в дальнейшем.
\begin{defn}
	Пересечение контентов пользователей $u_1$ и $u_2$, заданных на универсальном множестве характеристик
	$X$, --- это наибольшее нечеткое множество $c_X(v) = c_X(_1u)
	\bigcup c_X(u_2)$,
	содержащееся одновременно и в $c_X(u_1)$, и в $c_X(u_2)$,
	с функцией принадлежности $w_U$, заданной следующей формулой:
\end{defn}

\begin{equation}
				c_X(u_1) \bigcap c_X(u_2) = c_X(v): \forall x \in X w_U(v, x) =
				\min(w_U(u_1, x), w_U(u_2, x))
\end{equation}

\begin{defn}
	Пересечение контентов объектов $i_1$ и $i_2$, заданных на
	универсальном множестве характеристик
	$Y$, --- это наибольшее нечеткое множество
	$c_Y(j) = c_Y(i_1) \bigcup c_Y(i_2)$,
	содержащееся одновременно и в $c_Y(i)$, и в $c_Y(j)$,
	с функцией принадлежности, заданной следующей формулой:
\end{defn}
\begin{equation}
				c_Y(i_1) \bigcap c_Y(i_2) = c_Y(j): \forall y \in Y w_I(j, y) =
				\min(w_I(i_1, y), w_I(i_2, y))
\end{equation}

\begin{defn}
Объединение контентов пользователей $u_1$ и $u_2$,
	заданных на универсальном множестве $X$, --- это наименьшее
	нечеткое множество $c_X(v) = c_X(u_1) \bigcap c_X(u_2)$,
	включающее как $c_X(u_1)$, так и $c_X(u_2)$ с функцией
	принадлежности, заданной следующим образом:
\end{defn}
\begin{equation}
				c_X(u_1) \bigcup c_X(u_2) = c_X(v): \forall x \in X w_U(v, x) =
				\max(w_U(u_1, x), w_U(u_2, x))
\end{equation}

\begin{defn}
Объединение контентов объектов $i_1$ и $i_2$,
	заданных на универсальном множестве $Y$, --- это наименьшее
	нечеткое множество $c_Y(j) = c_Y(i_1) \bigcap c_Y(i_2)$,
	включающее как $c_Y(i_1)$, так и $c_Y(i_2)$ с функцией
	принадлежности, заданной следующим образом:
\end{defn}
\begin{equation}
				c_Y(i_1) \bigcup c_Y(i_2) = c_Y(j): \forall y \in Y w_I(j, y) =
				\max(w_I(i_1, y), w_I(i_2, y))
\end{equation}



%\begin{defn}
%Пусть $u^1$ и $u^2$ --- контенты пользователей. Говорят, что контенты $u^1$ и $u^2$ являются дополнением друг друга, если $u^1 = \overline{u^2}$ и $u^2 = \overline{u^1}$, 
%если $\forall$ $x \in X$ $w_U_1(x) = 1 - w_U_2(x)$
%\end{defn}
%
%\begin{defn}
%Пусть $i^1$ и $i^2$ --- контенты пользователей. Говорят, что контенты $i^1$ и $i^2$ являются дополнением друг друга, если $i^1 = \overline{i^2}$ и $i^2 = \overline{i^1}$, 
%если $\forall$ $y \in Y$ $w_I_1(y) = 1 - w_I_2(y)$
%\end{defn}

%ToDo показать на примере взаимосвязь. Вычислить косинус например и расстояние Хэмминга
%TODO: cite fuzzy logic
\section{Расстояние между пользователями и расстояние между объектами}
В разработанной модели будем пользоваться не мерой сходства, а
расстоянием. На основании значений расстояний будем определять,
выполняется отношение близости, или нет. Расстояние противоположно по
поведению и по семантике мере сходства. Там, где мера сходства растет,
расстояние убывает.

Введем расстояние между пользователями
$\rhu: U \times U \rightarrow [0,1]$ и объектами $\rhi: I \times I \rightarrow
[0,1]$ как обобщенное расстояние Хэмминга.

Расстояние между пользователями:
    \begin{equation}
		\label{fuz:rhu}
		\rhu(u,v) =
      \begin{cases}
		  \text{Не определено, если} & c_X(u) \bigcap c_X(v) = \varnothing\\
		  \frac{1}{|X|} \cdot \sum \limits_{x \in X} |w_U(u, x) -
		  w_U(v,x)| & \text{иначе}
      \end{cases}
    \end{equation}

Расстояние между пользователями:
    \begin{equation}
		\label{fuz:rhi}
		\rhi(i, j) =
      \begin{cases}
         \text{Не определено, если} & c_Y(i) \bigcap
		  c_Y(j) = \varnothing \\
        \frac{1}{|Y|} \cdot \sum \limits_{y \in Y} |w_I(i, y) - w_I(j,y)| & \text{иначе}
      \end{cases}
    \end{equation}

\subsubsection{Метрические свойства расстояния}
\begin{trm}
	\label{metric}
	Введенные функции $\rhi$ (\ref{fuz:rhi}) и $\rhu$ (\ref{fuz:rhu})
	обладают метрическими свойствами на подмножестве сравнимых агентов.
\end{trm}
Покажем выполнение метрических свойств для $\rhu$.
Доказательство для $\rhi$ проводится аналогично
с заменой соответствующих обозначений.

Опишем метрические свойства \cite{matan} и покажем выполнение каждого из них:
\begin{enumerate}
\item Положительность: $\rhu(u,v) \ge 0$
\item Симметричность: $\rhu(u,v) = \rhu(v,u)$
\item Неравенство треугольника: $\rhu(u, v) \le \rhu(u,z) + \rhu(v,z)$
\end{enumerate}
Выполнение свойства (1): $\rhu(u,v) = \frac{1}{|X|}
\cdot \sum \limits_{x \in X} |w(u,x) - w(v,x)|$. Каждый
элемент $|w(u,x) - w(v,x)| \ge 0$, а сумма неотрицательных
элементов неотрицательна.

Выполнение свойства (2): $\rhu(v,u) = \frac{1}{|X|} \cdot \sum \limits_{x \in X} |w_U(v,x) - w_U(u,x)| =
\frac{1}{|X|} \cdot \sum \limits_{x \in X} |w_U(u,x) - w_U(v,x)| = \rhu(u,v)$.

Выполнение свойства (3): докажем выполнение этого свойства с помощью метода математической индукции. Индукция по мощности $X$.
Рассмотрим его выполнение для $|X| = 1$. Рассмотрим пользователей $v,z$.
Так как $|X| = 1$, неравенство треугольника $\rho(v,z)$ запишется в виде

\begin{equation}\label{triangle-proof1}
|w_U(u,x) - w_U(v,x)| \le |w_U(u,x) - w_U(z,x)| + |w_U(v,x) - w_U(z,x)|
\end{equation}
Раскроем \ref{triangle-proof1} для каждой возможной ситуации:
\begin{itemize}
% z v u
	\item Пусть $(w_U(u,x) \ge w_U(v,x))$ $\wedge$ $(w_U(v,x) \ge w_U(z,x))$.
Тогда  неравенство \ref{triangle-proof1} примет следующий вид:
$w_U(u,x) - w_U(v,x) \le w_U(v,x) - w_U(z,x) + w_U(v,x) - w_U(z,x)$, то есть
$w_U(v,x) \ge w_U(z,x)$, что является истиной;


% v z u
\item Пусть $(w_U(u,x) \ge w_U(z,x))$ $\wedge$ $(w_U(z,x) \ge w_U(v,x))$.
Тогда  неравенство \ref{triangle-proof1} примет следующий вид:
$w_U(u,x) - w_U(v,x) \le w_U(u,x) - w_U(z,x) + w_U(z,x) - w_U(v,x)$, то есть
$w_U(z,x) \ge w_U(v,x)$, что является истиной;

% z u v
\item Пусть $(w_U(v,x) \ge w_U(u,x))$ $\wedge$ $(w_U(u,x) \ge w_U(z,x))$.
Тогда  неравенство \ref{triangle-proof1}
примет следующий вид:
	$w_U(v,x) - w_U(u,x) \le w_U(u,x) - w_U(z,x) + w_U(v,x) - w_U(z,x)$, то
		есть $w_U(u,x) \ge w_U(z,x)$, что является истиной;

% u z v
	\item Пусть $(w_U(v,x) \ge w_U(z,x))$ $\wedge$ $(w_U(z,x) \ge w_U(u,x))$.
Тогда  неравенство \ref{triangle-proof1}
примет следующий вид:
	$w_U(v,x) - w_U(u,x) \le w_U(z,x) - w_U(u,x) + w_U(v,x) - w_U(z,x)$, то
		есть $0 \ge 0$, что является истиной;

% v u  z
\item Пусть
	$(w_U(u,x) \ge w_U(v,x))$ $\wedge$ $(w_U(z,x) \le w_U(u,x))$.
Тогда  неравенство \ref{triangle-proof1} примет следующий вид:
		$w_U(u,x) - w_U(v,x) \le w_U(z,x) - w_U(u,x) + w_U(z,x) - w_U(v,x)$, то
		есть
		$w_U(z,x) \ge w_U(u,x)$, что является истиной;

% u v  z
\item Пусть
	$(w_U(v,x) \ge w_U(u,x))$ $\wedge$ $(w_U(z,x) \le w_U(v,x))$.
Тогда  неравенство \ref{triangle-proof1} примет следующий вид:
		$w_U(v,x) - w_U(u,x) \le w_U(z,x) - w_U(u,x) + w_U(z,x) - w_U(v,x)$, то
		есть
		$w_U(z,x) \ge w_U(v,x)$, что является истиной;
\end{itemize}

Пусть утверждение верно для $|X| = k$. Докажем, что утверждение верно
для $|X| = k + 1$. В этом случае неравенство треугольника запишется в следующем
виде: \\
$\frac{1}{k+1} \cdot \Big(\sum \limits_{l=1}^{k} |w_U(u,x_l) - w_U(v,x_l)| +
|w_U(u,x_{k+1}) - w_U(v,x_{k+1})| \Big)\le$ \\
$\Big(\frac{1}{k+1} \cdot \sum \limits_{l=1}^{k} |w_U(v,x_l) - w_U(z,x_l)| +
|w_U(v,x_{k+1}) - w_U(z,x_{k+1})|\Big) +$\\
$\Big(\frac{1}{k+1} \cdot \sum \limits_{l=1}^{k} |w_U(u,x_l) - w_U(z,x_l)| + |w_U(u,x_{k+1}) - w_U(z,x_{k+1})|\Big)$.

Так как утверждение выполняется для $|X| = k$, то\\
$\frac{1}{k+1} \Big(\sum \limits_{l=1}^{k} |w_U(v,x_l) - w_U(z,x_l)| + \sum \limits_{l=1}^{k} |w_U(u,x_l) - w_U(z,x_l)| -
\sum \limits_{l=1}^{k} |w_U(u,x_l) - w_U(v,x_l)|\Big) = A \ge 0$. Тогда неравенство треугольника для $|X| = k + 1$ запишется в виде
$|w_U(u,x_{k+1}) - w_U(v,x_{k+1})| \le |w_U(v,x_{k+1}) - w_U(z,x_{k+1})| + |w_U(v,x_{k+1}) - w_U(z,x_{k+1})| + A$.
Неравенство
$|w_U(u,x_{k+1}) - w_U(v,x_{k+1})| \le |w_U(v,x_{k+1}) - w_U(z,x_{k+1})| +
|w_U(v,x_{k+1}) - w_U(z,x_{k+1})|$ является верным по доказательству,
приведенному для $|X| = 1$.
Тогда $|w_U(u,x_{k+1}) - w_U(v,x_{k+1})| \le |w_U(v,x_{k+1}) - w_U(z,x_{k+1})|
+ |w_U(v,x_{k+1}) - w_U(z,x_{k+1})| + A$, так как $A$ --- неотрицательное число.

\section{Отношение близости пользователей и отношение близости объектов}
Определим отношение близости объектов:
\begin{equation}\label{rt}
  i \rt j \Leftrightarrow \overset{i}{\rho}(i,j) = 0
\end{equation}
Определим отношение близости пользователей:
\begin{equation}\label{ru}
	u \ru v \Leftrightarrow \overset{u}{\mathcal{\rho}}(u,v) \le
	\varepsilon_p
\end{equation}

По своей сути метрические функции расстояния являются количественными
показателями сходства элементов некоторого множества. Поэтому, отношения
близости, заданные через формулу расстояния могут считаться объективными.
При этом, если в РС используются меры сходства, высокий показатель которых
соответствует выполнению отношения близости, то тогда верны следующие теоремы:

\begin{trm}
	Отношение близости объектов, заданное в нечеткой модели (\ref{rt}), соответствует
	отношению близости объектов, заданному в ООМ (\ref{rt-ors}).
\end{trm}

Если $i \rt j$ в разработанной модели (\ref{rt}),
то $\rho(i, j) = 0$, и тогда $\di(i, j) = 1$, так как $i =
j$ и в РС используются симметричные меры сходства (использование
асимметричных мер сходства не имеет смысла). Так как $\di(i, j) =
1$, то $i \rt j$ для любого $\Delta_i$.

Рассмотрим следующий пример: $\di(i,j) = cos(\angle(i,j))$
и пусть $|c_Y| = 2$. Пусть $i, j$ такие, что $\rhi(i, j) = 0$, то есть
$w_I(i,y) = w_I(j,y)$. Тогда $\di(i, j) =
\frac{
	w_I(i,y_1) \cdot (w_I(i,y_1) +
	w_I(j,y_2) \cdot (w_I(j,y_2)
	} {
		\sqrt{w_I(i,y_1)^2 + w_I(i,y_2)^2} \cdot
		\sqrt{ (w_j(i,y_1))^2 + (w_I(j,y_2))^2   }
	} =
\frac{
	w_i(i,y_1) \cdot (w_i(i,y_1) +
	w_i(i,y_2) \cdot (w_i(i,y_2)
	} {
		\sqrt{w_i(i,y_1)^2 + w_i(i,y_2)^2} \cdot
		\sqrt{ (w_i(i,y_1))^2 + (w_i(i,y_2))^2   }
	} = 1$.
То есть $i \rt j$ для любого $\Delta_i$.

\begin{trm}
	Отношение близости пользователей, заданное в нечеткой модели (\ref{ru}), соответствует
	отношению близости пользователей, заданному в СОМ (\ref{user-sim1}).
\end{trm}

В СОМ $X = I$, $w_U(u, i) = \rho(u, i)$. Покажем, что если
отношение близости выполняется в нечеткой модели, то между пользователями
выполняется отношение близости в СОМ.
Докажем теорему методом индукции.
Пусть $n = 1$. Тогда
$u \ru v \Rightarrow |\rho(u, 1) - \rho(v, 1)| \le
\varepsilon_p$,
что полностью соответствует определению пользователей, между
которыми выполняется отношение близости (\ref{user-sim1}).

Пусть утверждение верно для $n = k$, то есть $\frac{1}{k} \cdot \sum
\limits_{i=1}^k|\rho(u, i) - \rho(v, i)| \le \varepsilon_p$.

Покажем, что теорема верна для $n = k + 1$.
$\rho(u, v) = \frac{1}{k + 1} \cdot \sum \limits_{i=1}^{k+1} |\rho(u,i) -
\rho(v,i)| \le $
$\varepsilon_p + \frac{1}{k + 1} \cdot |\rho(u, k+1) -
\rho(v, k+1)| \le \varepsilon_p$. Получаем, что
$|\rho(u, k+1) - \rho(v, k+1)| = 0$,
что соответствует формуле
(\ref{user-sim1}).
%Расстояние обладает противоположной семантикой семантике меры сходства, и там, где

%расстояние убывает, оценки сходства растет. Определим корреляцию между мерой
%сходства и расстоянием следующим образом:
%\begin{equation}\label{rho-sim}
%\rhi(i,j) = 1 - \di(i,j),
%\rhu(u,v) = 1 - \du(u,v)
%\end{equation}
%Введенная взаимосвязь является очень простой, однако
%она описывает ситуацию, когда $\rhi(i,j) = 0$, то контенты таковы, что, скорее
%всего, используемая мера сходства, например, косинус будет равна 1.
%но она выражает тот факт, что
%если 
%
%Данное уравнение следует из того факта, что для одинаковых элементов применямые
%оценки сходства приобретают значение, равное 1, а расстояния --- 0.
%
%TODO: ВЕЗДЕ УБРАТЬ 1 - \Delta, если речь идет о значении расстояния. Оно должно принадлежать окрестности.
%\subsection{Свойства отношения близости}
%В Главе 1 говорилось о важности выполнения свойства транзитивности отношения
%близости и было показано, что для КРТ выполнение этого свойства не
%гарантируется.
%Рассмотрим выполнение этого свойства в контентной модели.
%\begin{trm}\label{trans-rho}
%Отношения $\rt$, $ru$ в контентной модели обладает свойством транзитивности.
%\end{trm}
%
%Докажем выполнение свойства транзитивности отношения $\rt$. Доказательство
%свойства транзитивности для $\ru$ проводится аналогично.
%Выше было показано, что выполняется неравенство треугольника для введенных
%расстояний.
%Рассмотрим некоторые объекты $1, 2, 3$.
%Пусть $1 \rt 2$ $\wedge$ $2 \rt 3$. Так как функция
%обладает метрическими свойствами, то $\rhi(1,3) \le \rhi(1, 2) + \rhi(2, 3)$.
%Для любой сколь угодно малой окрестности $\varepsilon(0)$ можно составить такую окрестность $\xi(\varepsilon)$, что:
%\begin{enumerate}
%\item $\forall$ $\varepsilon_1$, $\varepsilon_2$ $\in \varepsilon(0)$ выполняется, что
%$\varepsilon_1+\varepsilon_2 \in \xi(\varepsilon)$.
%\item При $\varepsilon(0) \rightarrow 0 \Rightarrow \xi(\varepsilon) \rightarrow 0$.
%\end{enumerate}
%Тогда для любых $\rhi(1, 2)$ и $\rhi(2, 3)$ значение $\rhi(1,3) \in \xi(\varepsilon)$.
%В пределе, при $\varepsilon(0) \rightarrow 0$ получим, что и $\rhi(1,3) \rightarrow 0$, следуя свойству (2) окрестности
%$\xi(\varepsilon)$, то есть $\rhi(1,3) \le \epsilon_0 \in \varepsilon(0)$.
%То есть выполняется $1 \mathcal{R} 3$, а значит выполняется свойство транзитивности.

%% %
%% % ОЦЕНКА ЭФФЕКТИВНОСТИ
%% %
%% \section{Оценка эффективности $\mathcal{E}$}
%% %ToDo: расписать конкретно для полноты, не как f( от числа ), для точности, потом для кривой точность-полнота
%% % ну или сказать. Ну, или как-то потом обощить на другие оценки эффективности. Сказать, что все они f( от мощности )
%% % 
%% В разделе <<Анализ коллаборативных РС\rq  было показано, что не всегда существующие оценки эффективности
%% могут быть применены для выявление эффективности решения основных задач РС. В данном разделе предложен способ
%% введения оценки эффективности, основанный на использовании расстояния между пользователем и объектом. Свойства данного способа 
%% оценки эффективности показаны далее. 

%% Пусть мы обладаем алгоритмом, вычисляющим $\rho_{1}(u^a, t_{1})$ по контентам пользователя и объекта так, что:
%% \begin{equation}
%% |\rho_1(u^a,t_{1}) - \rho_{1}(u^a,t_{1})| \in \varepsilon(0), t_{1} \in T_{\times}
%% \end{equation}
%% где $\rho_{1}$ является {\it метрической функцией расстояния}. При этом будем считать, что значение поставленной оценки связано с расстоянием следующим образом:
%% $\rho_1(u^a, i^l) = 1 - \delta(u^a, i^l)$. Напомним так же, что $e^1 \mathbf{R} e^2 \Leftrightarrow \delta(e^1,e^2) > \Delta, e^i \in \{U,T\} \Leftrightarrow \rho_1(e^1,e^2) < 1 - \Delta$.

%% Характеристиками пользователя могут выступать не только его оценки. К примеру,
%% пользователь перед работой с РС может заполнить анкету \cite{bank}, которая состоит из характеристик, принадлежащих также и объектам, или из характеристик,
%% которые сопоставимы с характеристиками объектов. К примеру, это может набор кинематографических жанров, которые интересны пользователю и 
%% характерны для фильмов.  
%% При наличии алгоритма расчета $\rho_{1}(u^a, i^l)$, мы можем провести вычисление эффективности результатов 
%% по алгоритму, представленному в следующем алгоритме.
%% % ToDo в статье про полноту алгоритм сменен. Получается два разных упорядочвания. На этом надо заострить внимание.
%% \begin{algorithm}
%% \caption{Вычисление оценки эффективности $\mathcal{E}$}
%% \begin{algorithmic}[1]
%% \State Читаем тестовое множество $I^a_{\times}$
%% \State Читаем результирующее множество $I^a_{1}$
%% \State Упорядочиваем тестовое множество $I^a_{\times}$ по возрастанию $\rho_1(u^a, t_{\times})$, где 
%% $\rho_1(u^a, t_{\times})$ --- известная величина, равная $1 - \delta(u^a, t_{\times})$
%% \State Упорядочиваем тестовое множество $I^a_{1}$ по возрастанию $\rho_{1}(u^a, t_{1})$, где 
%% $\rho_{1}(u^a, t_{1})$ --- вычисленная величина. 
%% \State $\mathcal{E} = 0$
%% \For{$i = 1, i \le N$} \Comment{Для каждого $i$-ого объекта результирующего множества вычислим погрешность оценки и просуммируем общую погрешность результата.}
%% \State $\mathcal{E} = \mathcal{E} + |\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, i^i_{1})|$
%% \State $i = i + 1$
%% \EndFor
%% \State $\mathcal{E} = \frac{1}{N} \cdot \mathcal{E}$
%% \end{algorithmic}
%% \end{algorithm}

%% То есть для оценки эффективности вычисляется значение следующей функция:
%% \begin{equation}
%% \mathcal{E} = \frac{1}{N} \cdot  \sum \limits_{i=1}^N |\rho_{1}(u^a, i^i_{1}) - \rho_1(u^a, i^i_{\times})|,
%% \end{equation}

%% При этом множества $I^a_{\times}, I^a_{1}$ должны быть упорядочены по возрастанию значения расстояния $\rho_1(u^a, i^i_{\times})$ и
%% $\rho_{1}(u^a, i^i_{1})$ соответственно. Данная оценка расчитывет, насколько далеко объект в позиции $i$ результирующей выборки
%% отстоит по значению $\rho_1(u^a,i^i_{\times})$ от реальной ситуации.

%% Так как алгоритм вычисления $\rho_{1}(u^a, i^i_{1})$ обладает тем свойством, что вычисленное значение близко к реальному, то предложенный 
%% способ оценки заменяет процесс, когда пользователь сам поставит оценку $\delta_{1}(u^a, i^i_{1})$ рекомендованному объекту и 
%% вычислит его <<отдаленность\rq   --- то есть расстояние --- от своих предпочтений.

%% Такой способ оценки аннулирует проблемы, связанные со свойствами данных. Это связано с тем, что введенная оценка эффективности --- функция от вычисленной величины
%% $\delta_{1}(u^a, t_{1} \in I^a_{1})$ и известной $\delta(u^a, t_{\times} \in I^a_{\times})$, на которые не накладываются дополнительные условия, 
%% зависящие от данных. В отличии от оценки точности $\mathcal{E}_{\top}$ и $\mathcal{E}_p$, когда вычисленные и известные величины связаны эвристическими утверждениями ОРС и СРС, выполнение которых зависит от входных данных.
%% Таким образом, способ разбиения входного множества на тестовое и обучающее никак не влияет на значение оценки эффективности $\mathcal{E}$.
%% Значение этой оценки зависит от способа задания контентов пользователей, объектов и точности сопоставления характеристик пользователей
%% с характеристиками объектов.

%% Основывая выводы об эффективности решения не на косвенных признаках сходства объектов, а на вычислении актуального на данный момент времени\footnote{
%% При условии, что актуальные данные введены в систему пользователем. Это может быть обеспечено, 
%% к примеру, обязательным условием заполнением анкеты перед запросом на нахождение топового списка объектов.}
%% значения $\delta_{1}(u^a,t_{1})$, аннулируются проблемы, связанные с динамикой данных и их неоднородностью. 

%% Идеальным решением по $\mathcal{E}$ назовем $I^a_{1} = \{ i^l_{1}, \rho_{1}(u^a,i^l) \}$: 
%% $|\rho_{1}(u^a, i^l_{1}) - \rho_1(u^a, i^l_{\times})| \in \varepsilon(0)$. Будем говорить, что решение эффективно по $\mathcal{E}$, если
%% $|\rho_{1}(u^a, i^l_{1}) - \rho_1(u^a, i^l_{\times})| \in \varepsilon(0)$, $l=1..K \rightarrow N$.

%% %% Помимо точности существует ряд других оценок эффективностей решения, принадлежащих к разным классам. В связи с наличием многообразия оценок
%% %% у исследователей РС возникают вопросы: как сравнивать результаты, которые были оценены не коррелирующими оценками сходства, 
%% %% какую оценку сходства выбрть, как сравнить алгоритмы, протестированные на различных входных данных.

%% \section{Свойства оценка эффективности $\mathcal{E}$}
%% Назовем множество входных данных $I^a = \{ (i^l,\delta(u^a,i^l))| \delta(u^a,i^l) > \Delta \}$ 
%% (и в том числе $I^a_0,I^a_{\times})$) {\it репрезентативным}, если $\underset{l \rightarrow \infty} {\mathrm{\lim}}$  
%% $|\overline{\delta} - \delta(u^a,i^l)| = 0$, где $\overline{\delta}$ --- среднее значение оценок пользователя. 
%% То же распространяется и на расстояние: $\underset{l \rightarrow \infty} {\mathrm{\lim}}$  
%% $|\overline{\rho} - \rho_1(u^a,i^l)| = 0$
%% %Заметим, что  
%% %данные для задачи top-$N$ имеют свойство, что $\forall$ $(i^l, \delta(u^a,i^l))$: 
%% %$\delta(u^a,i^l)) > \Delta$.

%% \section{Применимость оценки эффективности $\mathcal{E}$ к целевой задаче top-$N$}
%% %ToDo: ВСЮ ПРИМЕНИМОСТЬ ПЕРЕПИСАТЬ, ЧТОБЫ НЕ БЫЛО 1 - \Delta
%% \begin{assert}
%%   Оценка эффективности $\mathcal{E}$ удовлетворяет целевой задаче top-$N$.
%% \end{assert}

%% {\bf Покажем, что} $\mathcal{E} \le \varepsilon_0 \Rightarrow \mathcal{E}_A \le \varepsilon_0$:
%% \begin{enumerate}
%% \item $\mathcal{E} \le \varepsilon_0 \Rightarrow |\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, i^i_{1})| \in \varepsilon(0), i=1..K, K \rightarrow N$.
%% Решение эффективно при условии, что разница расстояния мала для числа $K \rightarrow N$.
%% \item По данным задачи выполняется $\forall$ $i^i:$ $\rho_1(u^a, i^i_{\times}) < 1 - \Delta$, а, учитывая пункт (1) доказательства, получим, что 
%% $\rho_{1}(u^a, i^i_{1}) < 1 - \Delta$ для $i=1..K, K \rightarrow N$
%% \item Учитывая (11) и следствие пункта (2), получим, что $\rho_1(u^a, i^i_{1}) < 1 - \Delta$ для $i=1..K, K \rightarrow N$
%% %ToDo: перееписать как в статье
%% \item $\delta(u^a, i^i_{1}) = 1 - \rho_1(u^a, i^i_{1}) \Rightarrow \delta(u^a, i^i_{1}) > \Delta$ для $i=1..K, K \rightarrow N$ $\Rightarrow$
%% $\mathcal{E}_A < \varepsilon_0$
%% \end{enumerate}
%% %ToDO: Далее хороший момент, что в пределе будет насрать на дельта, надо и его расписать.
%% %% а при $\varepsilon(0) \rightarrow 0$ 
%% %% $\delta(u^a, i^i_{1}) \rightarrow 1$, а значит $\delta(u^a, i^i_{1}) > \Delta$ для любого $\Delta \in [0,1]$. 
%% %% Поэтому при $\varepsilon(0) \rightarrow 0$  


%% {\bf Покажем, что} $\mathcal{E}_A \le \varepsilon_0 \Rightarrow \mathcal{E} \le \varepsilon_0$:
%% \begin{enumerate}
%% \item $\mathcal{E}_A < \varepsilon_0$ $\Rightarrow$ $\delta(u^a, i^i_{1}) > \Delta$ для $i=1..K, K \rightarrow N \Rightarrow \rho_1(u^a, i^i_{1}) < 1 - \Delta$

%% \item $|\rho_1(u^a, i^i_{1}) - \rho_{1}(u^a, i^i_{1})| \in \varepsilon(0) \wedge$
%% $\rho_1(u^a, i^i_{1}) < 1 - \Delta \Rightarrow \rho_{1}(u^a, i^i_{1}) < 1 - \Delta$ для $i=1..K, K \rightarrow N$

%% \item Оценим $|\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, i^i_{1})|$: обе величины меньше $1 - \Delta$ и, учитывая репрезентативность множеств,
%% получим, что $\underset{i \rightarrow \infty} {\mathrm{\lim}}$  
%% $|\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, i^i_{1})| = 0 \Rightarrow \mathcal{E} < \varepsilon(0)$ для больших величин $N$

%% %% \item Учитывая репрезентативность, получаем, что:\\ $\mathcal{E}_A < \varepsilon_0$ $\Rightarrow$ $|\overline{\delta} - \delta(u^a, i^i_{1})| \in \varepsilon(0)$ 
%% %% для $i=1..K, K \rightarrow N$, где $\overline{\delta} = \frac{1}{M} \cdot \sum \limits_{t_0 | u^a \mathbf{R} i^l} \delta(u^a,t_0)$. $\overline{\delta}$ --- средняя высокая 
%% %% оценка активного пользователя, поставленная им понравившимся ему объектам.

%% %% \item $|\overline{\delta} - \delta(u^a, i^i_{1})| = |(1 - \overline{\delta}) - (1 - \delta(u^a, i^i_{1}))| = \overline{\rho} - \rho_1(u^a, i^i_{1})$

%% %% \item $\mathcal{E}_A < \varepsilon_0$ $\Rightarrow$ $|\overline{\rho} - \rho_1(u^a, i^i_{1})| \in \varepsilon(0)$ для $i=1..K, K \rightarrow N$

%% %% \item Из условия $|\overline{\rho} - \rho_{1}(u^a, i^i_{1})| \in \varepsilon(0)$ для $i=1..K, K \rightarrow N$ и (9) следует, что $\mathcal{E} < \varepsilon_0$.
%% %% Это следствие истинно, так как $\overline{\rho}$ --- среднее расстояние между активным пользователем и высоко оцененным им объектом, то есть таким объектом $t_0$, что
%% %% $u^a \mathbf{R} t_0$. Так как $|\overline{\rho} - \rho_{1}(u^a, i^i_{1})| \in \varepsilon(0)$, то вычисленное расстояние

%% %% \item По данным задачи $\forall$ $i^i:$ $\delta(u^a, i^i_{\times}) > \Delta$, поэтому $|\delta(u^a, i^i_{1}) - \delta(u^a, i^i_{\times})| \in \varepsilon(0)$
%% %% для $i=1..K, K \rightarrow N$
%% %% \item $|\delta(u^a, i^i_{1}) - \delta(u^a, i^i_{\times})| = |(1 - \delta(u^a, i^i_{\times})) - (1- \delta_{1}(u^a, i^i_{1}))| = |\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, i^i_{1})|$
%% %% \item $|\delta(u^a, i^i_{1}) - \delta(u^a, i^i_{\times})| \in \varepsilon(0)$ для $i=1..K, K \rightarrow N$ $\Rightarrow$ 
%% %% $|\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, i^i_{1})| \in \varepsilon(0)$
%% %% \end{itemize}

%% %% $\mathcal{E}_A \le \varepsilon_0 \Rightarrow \delta(u^a, i^i_{\times}) \ge \Delta$ для $i=1..K$, $K \rightarrow N$.
%% %% Поэтому $|\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, t_{1})| \le \varepsilon_0$ для $i=1..K$, $K \rightarrow N$, поэтому
%% %%  $\mathcal{E} \le \varepsilon_0$.
%% \end{enumerate}

%% {\bf !!!!!!! Правльное утверждение !!!!!!!}

%% \begin{assert}
%% Введенная оценка эффективности может применяться для выявления качества решения задачи top-$N$.
%% \end{assert}

%% \section{Применимость оценки эффективности $\mathcal{E}$ к целевой задаче прогнозирования}
%% \begin{assert}
%%   Оценка эффективности $\mathcal{E}$ удовлетворяет целевой задаче прогнозирования.
%% \end{assert}

%% По целевой задаче необходимо определить такую $\delta_{1}(u^a,t_{\times})$ такую, что 
%% $|\delta_{1}(u^a,t_{\times}) - \delta(u^a,t_{\times})| \in \varepsilon(0)$. Если решение задачи прогнозирования
%% эффективно, то тогда $|\delta_{1}(u^a,i^i_{\times}) - \delta(u^a,i^i_{\times})| \in \varepsilon(0)$ для $i=1..K$, 
%% $K \rightarrow N$. 

%% Решение задачи прогнозирования эффективно по оценке эффективности $\mathcal{E}$, если $|\rho_{1}(u^a,i^i_{\times}) - \rho_1(u^a,i^i_{\times})| \in \varepsilon(0)$ для $i=1..K$, $K \rightarrow N$. Так как 
%% $\rho_{1}(u^a,i^i_{\times}) = 1 - \delta_{1}(u^a,i^i_{\times}), \rho_1(u^a,i^i_{\times}) = 1 - \delta(u^a,i^i_{\times})$, 
%% то решение эффективно, если $|\delta(u^a,i^i_{\times}) - \delta_{1}(u^a,i^i_{\times})| \in \varepsilon(0)$ для $i=1..K$, 
%% $K \rightarrow N$, что соответствует эффективности по целевой задаче.

%% \section{Корреляция $\mathcal{E}_{\top}$ и $\mathcal{E}$}
%% Покажем, что в тех случаях, когда для оценки эффективности может применяться $\mathcal{E}_{\top}$ --- 
%% то есть входные данные таковы, что выполняется утверждение ОРС --- верно, что $\mathcal{E}_{\top} \le \varepsilon_0 \Rightarrow \mathcal{E} \le \varepsilon_0$
%% и $\mathcal{E} \le \varepsilon_0 \Rightarrow \mathcal{E}_{\top} \le \varepsilon_0$.

%% {\bf Покажем, что} $\mathcal{E}_{\top} \le \varepsilon_0 \Rightarrow \mathcal{E} \le \varepsilon_0$:
%% \begin{enumerate}
%% \item Учитывая свойства входных данных и выполнение утверждения ОРС, верно, что 
%% $u^a \mathbf{R} t_{\times} \wedge i^i_{1} \mathbf{R} t_{\times} \Rightarrow u^a \mathbf{R} t_{1}$,
%% где $i^i_{1} \mathbf{R} t_{\times} \Leftarrow$ $\mathcal{E}_{\top} \le \varepsilon_0$ для $i=1..K$, $K \rightarrow N$

%% \item $u^a \mathbf{R} i^i_{1} \Rightarrow$ $\rho_1(u^a,i^i_{1}) < 1 - \Delta$ для $i=1..K$, $K \rightarrow N$

%% \item Учитывая (11) и вывод пункта (2) получим, что $\rho_{1}(u^a,i^i_{1}) < 1 - \Delta$ 
%% для $i=1..K$, $K \rightarrow N \Rightarrow \mathcal{E} < \varepsilon_0$

%% \item Оценим $|\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, i^i_{1})|$: обе величины меньше $1 - \Delta$ и, учитывая репрезентативность множеств, получим, что $\underset{i \rightarrow \infty} {\mathrm{\lim}}$  
%% $|\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, i^i_{1})| = 0 \Rightarrow \mathcal{E} < \varepsilon(0)$ для больших величин $N$
%% \end{enumerate}

%% {\bf Покажем, что} $\mathcal{E} \le \varepsilon_0 \Rightarrow \mathcal{E}_{\top} \le \varepsilon_0$: 
%% \begin{enumerate}
%% \item $\mathcal{E} \le \varepsilon_0 \Rightarrow |\rho_1(u^a, i^i_{\times}) - \rho_{1}(u^a, i^i_{1})| \in \varepsilon(0), i=1..K, K \rightarrow N$. 
%% \item Так как функции $\rho$ и $\rho_{1}$ обладают метрическими свойствами, то 
%% $\rho_{1}(i^i_{\times},i^i_{1}) \le \rho_1(u^a,i^i_{\times}) + \rho_{1}(u^a,i^i_{1}) \Rightarrow \rho_{1}(i^i_{\times},i^i_{1}) \in \varepsilon(0) \Rightarrow $
%% $\rho_{1}(i^i_{\times},i^i_{1}) < 1 - \Delta$ для $i=1..K, K \rightarrow N \Rightarrow $ $t_{1} \mathbf{R} t_{\times} \Rightarrow$ $\mathcal{E}_{\top} < \varepsilon_0$
%% %% $(1 - \Delta) + (1 - \Delta)$. При $\Delta \rightarrow 1$ значение $\rho_{1}(i^i_{\times},i^i_{1}) \rightarrow 0 \Rightarrow$ 
%% %% $i^i_{\times} \mathbf{R} i^i_{1}$ для $i=1..K, K \rightarrow N \Rightarrow$ $\mathcal{E}_{\top} \le \varepsilon_0$.
%% \end{enumerate}

%% \begin{assert}
%% При выполнении утверждения ОРС оценка эффективности $\mathcal{E}$ коррелирует с оценкой эффективности $\mathcal{E}_{\top}$.
%% \end{assert}

%% \section{Корреляция $\mathcal{E}_{\top}$ и $\mathcal{E}$}
%% \begin{assert}
%% Оценка эффективности $\mathcal{E}_p$ коррелируют с оценкой эффективности $\mathcal{E}$
%% \end{assert}

%% Данное утверждение следует из того, что 
%% $\rho_{1}(u^a,i^i_{\times}) = 1 - \delta_{1}(u^a,i^i_{\times}), \rho_1(u^a,i^i_{\times}) = 1 - \delta(u^a,i^i_{\times})$.

%% \section{Решение задач во введенной модели}
%% Опишем возможные способы решения основных задач РС во введенной модели. Решение обеих задач основано на использовании
%% введенного расстояния между пользователем и объектом.

%% \section{Решение задачи top-$N$}
%% Задача top-$N$ может быть решена {\it линейным поиском} схожих с активным пользователем объектов. 

%% \begin{algorithm}\label{mysolve-topn}
%% \caption{Решение задачи top-$N$}
%% \begin{algorithmic}[1]
%% \State $T' \gets T \setminus \{ t_0 | t_0 \in I^a_0\}$
%% \State $n \gets 1$
%% \State $I^a_{1} \gets \varnothing$
%% \For{$i^l \in T'$ $\wedge$ $n \le N$}
%%   \If {$\rho_{1}(u^a,i^l) < 1 - \Delta$}
%%   \State $I^a_{1} \gets I^a_{1} \bigcup \{(i^l, \rho_{1}(u^a,i^l))\}$
%% 	\State $n \gets n + 1$
%%   \EndIf
%% \EndFor
%% \end{algorithmic}
%% \end{algorithm}

%% \section{Анализ решения задачи top-$N$}
%% \begin{assert}
%% Решение \ref{mysolve-topn} эффективно
%% \end{assert}

%% Рассмотрим, чему равно значение оценки эффективности на решении, предложенном алгоритмом \ref{mysolve-topn}.
%% $\mathcal{E}(E_{1}, E_{\times}) = \sum \limits_{i=1}^N |\rho_{1}(u^a,t_{\times}^i) - \rho_1(u^a,i^i)|$. 
%% Для каждой пары выполняется $\rho_{1}(u^a,t_{\times}^i) < 1 - \Delta$, $\rho_1(u^a,i^i) < 1 - \Delta$. 
%% При $\Delta \rightarrow 1$ получаем, что $|\rho_{1}(u^a,t_{\times}^i) - \rho_1(u^a,i^i)| \in \varepsilon(0)$ для
%% $i=1..N$. Поэтому можно считать, что решение задачи, полученное при помощи алгоритма \ref{mysolve-topn} эффективно.

%% Асимптотическая сложность решения задачи top-$N$ в худшем случае равна $O(|T|)$, так как для ее решения рассчитать 
%% $|T|$ раз расстояние $\rho_{1}(u^a,i^l)$.

%% \section{Решение задачи прогнозирования}
%% Решение задачи прогнозирования заключается в расчете значения $1 - \rho_{\times}(u^a, t_{\times})$. 
%% \begin{algorithm}\label{mysolve-p}
%% \caption{Решение задачи top-$N$}
%% \begin{algorithmic}[1]
%% \State $\delta_{\times}(u^a, t_{\times}) \gets 1 - \rho_{\times}(u^a, t_{\times})$
%% \end{algorithmic}
%% \end{algorithm}

%% \section{Анализ решения задачи прогнозирования}
%% Решение, полученно при помощи алгоритма \ref{mysolve-p} является эффективным, если 
%% $\rho_{1}(u^a,t_{\times})$ таково, что 
%% $|\rho_{1}(u^a,t_{\times}) - \rho_1(u^a,t_{\times})| \in \varepsilon(0)$. Так
%% как $|\rho_{1}(u^a,t_{\times}) - \rho_1(u^a,t_{\times})| \in \varepsilon(0)$, то
%% $\mathcal{E} = \sum \limits_{i=1}^{M} |\rho_{1}(u^a,i^i_{\times}) - \rho^i(u^a,t_{\times})| < \varepsilon_0$.

%% Асимптотическая сложность решения задачи прогнозирования равна $O(C)$, где $C$ --- константа, 
%% так как для решения необходимо произвести единичный расчет функции расстояния.

%% \section{Вывод}
%% Решения основных задач во введенной модели являются эффективными по отношению к целевой задаче для любых входных данных и 
%% обладают асимптотической сложностью на порядок меньшей по сравнению с решениями основных задач в эвристических коллаборативных РС.
