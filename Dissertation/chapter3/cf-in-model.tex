%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Применение коллаборативных правил вывода в нечеткой модели}
Разработанная нечеткая модель не является жесткой альтернативой,
перечеркивающей применение коллаборативных правил вывода, допускается
применение методов коллаборативной фильтрации, но предлагается использовать
способ представления данных и отношения близости
способами нечеткой модели.

Выше говорилось, что при применении $\Pi_O$ или $\Pi_C$
не всегда
получение эффективного решения по критерию качества
зависит от меры сходства и порогового значения (\ref{krt-params}).
Разработанная нечеткая модель позволяет
применить $\Pi_O$ и $\Pi_C$ так, чтобы выполнялись
достаточные и необходимые условия эффективности.
%========================================================================
\subsection{Применение правил вывода объектно-ориентированной модели}
Рассмотрим объектно-ориентированную модель при представлении контентов в виде
нечетких множеств и при применении расстояния $\rhi$ между объектами для определения
отношения близости объектов.
%----------------------------------------------------------------------
\subsubsection{Решение задачи $topN$}
Напомним, что решение задачи $topN$
при применении $\Pi_O$ заключается в формировании кластера $\nit = \{ i : i \rt I_0 \}$.
Необходимое условие точности решения (\ref{transAssert1})
заключается в выполнении свойства
транзитивности отношения близости,
что зависит от меры сходства и порогового значения \ref{krt-params}.
В нечеткой модели введена функция расстояния
$\rhi$, определим отношение $i \rt I_0$ следующим образом:
\begin{equation}
	\label{mod-itopn}
	i \rt I_0 \Leftrightarrow \exists i_0 \in I_0: \rhi(i, i_0) = 0
\end{equation}

\begin{trm}
	В нечеткой модели гарантируется выполнение необходимого
	условия эффективности решения (\ref{transAssert1}).
\end{trm}
Выполнение условия (\ref{transAssert1}) достигается за счет метрических свойств
используемой функции расстояния.

По утверждению (\ref{assertORS1}) получаем, что $\forall i_0$ $\exists i_{\bot}: i_0
\rt i_{\bot}$. По построению решения в результирующее множество входят такие
объекты $i$, что: $\exists i_0: \rhi(i_0, i) = 0$. Но также $\exists i_{\bot}:
\rhi(i_0, i_{\bot}) = 0$. Так как функция $\rhi$ обладает
метрическими свойствами, то $\rhi(i, i_{\bot}) \le \rhi(i_0, i) + \rhi(i_0,
i_{\bot}) = 0$, и потому $i \rt i_{\bot}$. То есть выполняется
необходимое свойство транзитивности: $(i \rt i_0) \wedge (i_0 \rt i_{\bot})
\Rightarrow i \rt i_{\bot}$.

\begin{trm}
	\label{trm:fuz-eff-oom}
	Применение правила вывода $\Pi_O$ в нечеткой модели более эффективно
	по критерию качества, чем применение того же правила в ООМ.
\end{trm}
Эта теорема следует из того, что в нечеткой модели выполняется
необходимое условие эффективности решения (\ref{transAssert1}).
%-------------------------------------------------------------------------------
%\subsubsection{Решение задачи прогнозирования}
%Напомним, что для решения задачи прогнозирования при применении $\Pi_O$ строится кластер
%$\nip = \{ i_0 : i \rt i_{\bot} \}$. Введем следующую модификацию:
%
%\begin{equation}
%\label{mod-ip1}
%\nip = \{i_0: \rhi(i_0, i_{\bot}) = 0 \}
%\end{equation}
%
%\begin{trm}
%В нечеткой модели гарантируется выполнение
%достаточного условия эффективности решения
%(\ref{suff-cond-pred-ors}).
%\end{trm}
%
%Оценим значение расстояния $\rhi(i, j)$ для любых $i,j \in \nip$.
%Так как функция $\rhi$ обладает свойством неравенства треугольника, то
%$\rhi(i, j) \le \rhi(i, i_{\bot}) + \rhi(j, i_{\bot})$.
%$\rhi(i, i_{\bot}) = 0, \rhi(j, i_{\bot}) = 0$ по модификации алгоритма.
%Поэтому $\rhi(i, j) = 0 \Rightarrow i \rt j$. Таким образом между любыми
%элементами кластера выполняется отношение близости свойство транзитивности
%отношения близости,
%то есть выполняется
%достаточное условие
%$(i_{\bot} \rt i) \wedge (i_{\bot} \rt j) \Rightarrow i \rt j, i,j \in \nit$.
%\begin{trm}
%	\label{trm:fuz-eff-com}
%	Применение правила вывода $\Pi_C$ в нечеткой модели более эффективно
%	по критерию качества, чем применение того же правила в СОМ.
%\end{trm}
%Эта теорема следует из того, что в нечеткой модели выполняется
%достаточное условие эффективности решения (\ref{suff-cond-pred-ors}).
%
%\paragraph{Модификация алгоритма решения задачи прогнозирования}
%Отношение близости объектов, заданное формулой (\ref{rt}) и
%на котором основано решение задачи прогнозирования,
%определяется по равенству расстояния нулю, однако такие значения для
%реальной РС могут быть неподходящими. Можно представить систему,
%которая оперирует с бинарными значениями характеристик \{0, 1\}, а объекты
%считаются в этой системе схожими, если половина признаков объекта совпадает,
%то есть если $\rhi(i, j) \le 0,5$, то $i \rt j$. Для таких случаев, когда
%$(i \rt j) \Leftrightarrow (\rhi(i, j) \le \varepsilon \ne 0)$,
%приведем модификацию алгоритма составления соседей, при применении которой
%в построенном кластере будет выполняться свойство транзитивности отношения
%близости, то есть достаточное условие аккуратности решения задачи
%прогнозирования (\ref{suff-cond-pred-ors}).
%
%При добавлении нового объекта $i$ в момент формирования
%будем соблюдать выполнение следующего условия:
%\begin{equation}
%	\label{mod-ip2}
%	(i \rt i_{\bot}) \wedge (i \rt i^{\bigcup}) \wedge (i \rt i^{\bigcap})
%\end{equation}
%где $i^{\bigcup} = i^1 \bigcup i^2 \bigcup ... i^{|\nip|},
%i^{\bigcap} = i^1 \bigcap i^2 \bigcap ... i^{\nip}$
%
%\begin{figure}[htb]
%\caption{Модифицированный алгоритм решения задачи прогнозирования}
%\label{alg-mod-ip2}
%%\begin{algorithm}
%\begin{algorithmic}[1]
%\State $\nip \gets \varnothing$
%	\For {$i \in I^a_0$}
%	\If {$\rhi(i, i_{\bot}) \le \varepsilon$}
%		\If {$|\nit| = 0$}\Comment{Если множество соседей еще пусто, то добавляем
%		объект $i$}
%		\State $\nit \gets \nit \bigcup \{ i \}$
%		\State $i^{\bigcup} \gets i \bigcup i_{\bot}$
%		\State $i^{\bigcap} \gets i \bigcap i_{\bot}$
%		\State $P^a \gets \rhu(u_a, i)$
%		\ElsIf {$i \rt i^{\bigcup} \wedge i \rt i^{\bigcap}$}
%		\State $\nit \gets \nit \bigcup \{ i \}$
%		\State $i^{\bigcup} \gets i \bigcup i^{\bigcup}$
%		\State $i^{\bigcap} \gets i \bigcap i^{\bigcap}$
%		\State $P^a \gets \rho(u_a, i)$
%		\EndIf
%	\If{$|\nup|$}\Comment{$M$ --- максимальное число объектов в кластере}
%	\State Стоп
%	\EndIf
%	\EndIf
%	\EndFor
%	\State $\rho(u_a,i_{\bot}) \gets p(P^a)$
%\end{algorithmic}
%%\end{algorithm}
%\end{figure}
%
%\begin{trm}
%	Модифицированный алгоритм решения задачи прогнозирования
%	(\ref{alg-mod-ip2})
%	гарантирует выполнение достаточного условия аккуратности решения
%	\ref{suff-cond-pred-ors}.
%\end{trm}
%Докажем при помощи метода индукции по мощности множества $|Y|$.
%На первом шаге индукции $|Y|=1$, то есть $c_Y(i) = \{ y | w_I(i, y) \}$.
%
%По построению кластера для нового объекта $i$
%выполняется $i \rt i^{\bigcup} \wedge i \rt i^{\bigcap}$, то есть
%$\nu_i(y) - \mathrm{min}\{ \nu_j(y), j \in \nit \} \le \varepsilon$ и
%$\mathrm{max}\{ \nu_j(y), j \in \nit \} - \nu_i(y)
%\le \varepsilon$ по определению расстояния и отношения близости объектов.
%
%Покажем, что для нового элемента $i$, и $\forall$ $j \in \nit$
%верно
%$|\nu(y) - \nu(y)| \le \varepsilon$. Для этого покажем, что
%$|\nu(y) - \nu(y)| < |\nu(y) - \mathrm{min}\{ \nu_j(y), j \in \nit \}|$:
%
%\begin{enumerate}
%	\item Пусть $\nu_i(y) \ge \nu_j(y)$, тогда \\
%$\nu_i(y) - \nu_j(y) < \nu_i(y) - \mathrm{min}\{ \nu_k(y), k \in
%\nit \} \le \varepsilon$
%\item Пусть $\nu_i(y) < \nu_j(y)$, тогда \\
%$\nu_j(y) - \nu_i(y) < \mathrm{max}\{ \nu_k(y), k \in \nit\} -
%\nu_i(y) \le \varepsilon$
%\end{enumerate}
%
%Пусть утверждение выполняется для $|c_Y| = l-1$.
%Покажем, что для множества мощности $l$ выполняется
%$\frac{1}{l} \cdot \sum \limits_{k=1}^{l-1}
%|\nu_i(y^k) - \nu_j(y^k)| \le \varepsilon$\\
%
%Пусть $\nu_i(y^k) \ge \nu_j(y^k)$, тогда:\\
%
%$\rhi(i, j) = \sum \limits_{k=1}^{l-1}
%|\nu_i(y^k) - \nu_j(y^k)|$ +
%$(\nu_k(y^l) - \nu_j(y^l)) <$\\
%
%$\sum \limits_{k=1}^{l-1} |\nu_i(y^k) - \nu_j(y^k)|$
%+ $(\nu_i(y^l) - \mathrm{min}\{ \nu_j(y^l), j \in \nip)\} <$  \\
%
%$\sum \limits_{k=1}^{l-1}
%|\nu_i(y^k) - \mathrm{min}\{ \nu_j(y^k), j \in \nip \}|$
%+ $(\nu_i(y^l) - \mathrm{min}\{ \nu_j(y^l), j \in \nip \}) = $
%$\rhi(i, i^{\bigcap}) \le \varepsilon$
%
%Пусть $\nu_i(y^k) < \nu_j(y^k)$, тогда:\\
%
%$\rhi(i, j) = \sum \limits_{k=1}^{l-1}
%|\nu_i(y^k) - \nu_j(y^k)|$ +
%$(\nu_k(y^l) - \nu_j(y^l)) <$\\
%
%$\sum \limits_{k=1}^{l-1} |\nu_i(y^k) - \nu_j(y^k)|$
%+ $(\mathrm{max}\{ \nu_j(y^l), j \in \nip \} - \nu_i(y^l)) <$  \\
%
%$\sum \limits_{k=1}^{l-1}
%|\mathrm{max}\{ \nu_j(y^k), j \in \nip \} - \nu_i(y^k)|$
%+ $\mathrm{max}\{ \nu_j(y^l), j \in \nip \} - (\nu_i(y^l)) = $
%$\rhi(i, i^{\bigcup}) \le \varepsilon$.

\subsection{Применение правил вывода субъектно-ориентированной модели}
Рассмотрим субъектно-ориентированную модель при представлении контентов в виде
нечетких множеств и при применении расстояния $\rhu$ между пользователями для определения
отношения близости пользователей.
\subsubsection{Решение задачи прогнозирования}
Напомним, для что решения задачи $pred$ в СОМ
строится кластер
$\nup = \{ u_a : (u_a \ru u) \wedge (\exists \rho(u, i_{\bot})) \}$.
Необходимое (\ref{nec-cond-pred-srs}) и достаточное (\ref{suf-cond-pred-srs})
условия эффективности решения задачи $pred$
заключается в выполнении на кластере $\nup$ свойства
транзитивности отношения близости,
что зависит от меры сходства и порогового значения \ref{krt-params}.
В нечеткой модели введем следующую модификацию составления
кластера соседей:

\begin{equation}
	\label{mod-of-p-ub}
	\nup = \{ u : (\rhu(u_a, u) \le \frac{1}{2} \cdot \varepsilon_p) \wedge
	(\exists \rho(u, i_{\bot})) \}
\end{equation}
Для нечеткой модели при применении $\Pi_C$ для решения задачи
$pred$ меняется лишь алгоритм составления множества соседей, дальнейшее решение остается прежним.

\begin{figure}[h]
	\caption{Модифицированный алгоритм построения множества соседей для активного
	пользователя $u_a$ при решении задачи прогнозирования}
	\label{alg-mod-up1}
	%\begin{algorithm}
		\begin{algorithmic}[1]
			\State $\nup \gets \varnothing$
			\State $k \gets 0$
			\For {$u \gets 1 \to m$}
			\If{$\rhu(u_a,  u) \le \frac{1}{2} \varepsilon_p$}
			\State $\nup \gets \nup \bigcup \{ u \}$
			\State $k \gets k + 1$
			\EndIf
			\If{$k > M$}\Comment{Ограничение на размер множества соседей}
			\State Стоп
			\EndIf
			\EndFor
		\end{algorithmic}
	%\end{algorithm}
\end{figure}

\begin{trm}
	\label{trm:fuz-eff-com}
	Модифицированный алгоритм составления кластера соседей
	(\ref{alg-mod-up1})
	гарантирует выполнение необходимого (\ref{nec-cond-pred-srs}
) и
	достаточного (\ref{suf-cond-pred-srs})
эффективности решения
		\end{trm}
Оценим значение расстояния $\rhu(u, v)$ для любых $u,v \in \nup$.
Так как функция $\rhu$ обладает свойством неравенства треугольника, то
$\rhu(u, v) \le \rho(u_a, u) + \rhi(u_a, v)$. По построению кластера
(\ref{alg-mod-up1}) выполняется, что
$\rhu(u_a, u) \frac{1}{2} \cdot \varepsilon_p$
и
$\rhu(u_a, v) \frac{1}{2} \cdot \varepsilon_p$. Поэтому $\rhu(u,v) \le
\varepsilon_p$, то есть выполняется
необходимое и достаточное условие
$u_a \ru u \wedge u_a \ru v  \Rightarrow u \ru v, \forall u,v \in \nup$.

%\paragraph{Способ 2}
%При создании реальной РС, моделью которой является нечеткая модель при применении
%$\Pi_C$ и модификации алгоритма построения кластера соседей первым способом
%(\ref{alg-mod-up1}),
%отношение близости, заданное формулой (\ref{ru}) может быть неподходящим,
%так как пороговое значение $\varepsilon_p$ малая величина, близкая нулю.
%И значение $\varepsilon_p$ может быть слишком маленьким для применения
%в реальной РС.
%
%Например, в системе используется бинарная шкала для близостей, задаваемых
%пользователями. Так как близости являются характеристиками для нечеткой СОМ,
%то это значит, что $w_U(u, x) \in \{0,1\}$. Пусть РС используется в
%букинистическом интернет-магазине, тогда пользователей можно назвать соседями,
%если они приобретают от 40\% до 100\% одних и тех же книг.
%Для таких пользователей $u \ru v \Leftrightarrow \rhu(u,v) \in [0; 0,6]$,
%и тогда по свойству неравенства треугольника $\rhu(u, v) \in [0; 1,2]$.
%
%При использовании иного порогового значения
%для установления
%выполнения отношения близости необходимое и достаточное условие аккуратности
%решения могут не выполняться при применении алгоритма формирования
%кластера (\ref{alg-mod-up1}). Рассмотрим пример, приведенный выше.
%Предположим, что $\varepsilon_p = 0,8$, $(u_a \ru u) \wedge (u_a \ru v)$, тогда
%$\rho(u, v) \in [0;0,4]$ (по неравенству треугольника).
%Вполне вероятно, что значение $\rho(u,v)$ окажется больше 0,2.
%Например, пользователь $u_a$ приобрел книги 1-10 включительно,
%пользователь $u$ --- книги 1-4 включительно,
%пользователь $v$ --- книги 4-10 включительно. Между пользователями $u, v$
%отношение близости не выполняется, то есть нарушаются необходимое и достаточное
%условия.
%
%Для таких систем, где требуется использование порогового значения $\varepsilon$ не близкого
%нулю введем следующий алгоритм составления множества соседей $\nup$:
%новый пользователь $u$ добавляется в кластер, если:
%\begin{equation}\label{method}
%	(u \ru u_a) \wedge (u \ru u^{\bigcup}) \wedge (u \ru u^{\bigcap})
%\end{equation}
%где $u^{\bigcup} = u^1 \bigcup u^2 \bigcup ... u^{|\nup|},
%u^{\bigcap} = u^1 \bigcap u^2 \bigcap ... u^{|\nup|}, u^k \in \nup$.
%
%\begin{figure}[h]
%	\caption{Модифицированный алгоритм построения множества соседей для активного
%	пользователя $u_a$ при решении задачи прогнозирования. Способ 2.}
%	\label{alg-mod-up2}
%	%\begin{algorithm}
%		\begin{algorithmic}[1]
%			\State $\nup \gets \varnothing$
%			\For {$u \gets 1 \to m$}
%				\If{ $(u_a \ru u) \wedge (\exists \rho(u, i_{\bot})) \wedge (k < M)$
%				} \Comment{$M$ --- максимальное число пользователей в кластере}
%					\If{$|\nup| = 0$}
%						\State $\nup \gets \nup \{u\}$
%						\State $u^{\bigcup} \gets u$
%						\State $u^{\bigcap} \gets u$
%					\ElsIf{
%					$(u $
%					$\ru$
%					$\u^{\bigcup})$ $\wedge (u$
%					$\ru$
%					$u^{\bigcap})$}
%						\State $\nup \gets \nup \bigcup \{ u \}$
%						\State $u^{\bigcap} \gets u \bigcap u^{\bigcap}$
%						\State $u^{\bigcup} \gets u \bigcup u^{\bigcup}$
%					\EndIf
%				\EndIf
%				\If{$|\nup|$}\Comment{$M$ --- максимальное число объектов в кластере}
%				\State Стоп
%				\EndIf
%			\EndFor
%			\State $\rho(u_a,i_{\bot}) \gets p\{ \rho(u,i_{\bot}) \in \nup \})$
%		\end{algorithmic}
%	%\end{algorithm}
%\end{figure}
%
%
%\begin{trm}
%	Модифицированный алгоритм составления кластера при решении задачи $pred$
%	(\ref{alg-mod-up2}) гарантирует выполнение необходимого (\ref{nec-cond-pred-srs}
%) и
%	достаточного (\ref{suff-cond-pred-srs}) условия эффективности решения при любых пороговых значений
%	$[0,1]$.
%\end{trm}
%
%Докажем с помощью метода индукции по мощности множества характеристик
%пользователей $c_X$. Так как для КРС характеристиками пользователей являются
%идентификаторы объектов, то индукция проводится по множеству $I$.
%Рассмотрим ситуацию, когда есть $|I| = 1$.
%
%По построению кластера $\nup$ для нового пользователя $u$
%выполняется $u \ru u^{\bigcup} \wedge u \ru u^{\bigcap}$, то есть
%$\rho(u, i) - \mathrm{min}\{ \rho(v, i), v \in \nup \} \le \varepsilon$ и
%$\mathrm{max}\{ \rho(v, i), v \in \nup\} - \rho(u, i)
%\le \varepsilon$ по определению расстояния (\ref{rho-user}) и
%близких пользователей (\ref{user-sim1}).
%
%Покажем, что для нового элемента $u$, и $\forall$ $v \in \nup$ верно
%$|\rho(u, i) - \rho(v, i)| \le \varepsilon_p$. Для этого покажем, что
%$|\rho(u, i) - \rho(v, i)| < |\rho(u, i) - \mathrm{min}\{ \rho(v, i),
%v \in \nup \}|$:
%
%\begin{enumerate}
%\item Пусть $\rho(u, i) \ge \rho(v, i)$, тогда \\
%$\rho(u, i) - \rho(v, i) < \rho(u, i) - \mathrm{min}\{ \rho(v, i),
%v \in \nup \} \le \varepsilon_p$
%\item Пусть $\rho(u, i) < \rho(v, i)$, тогда \\
%$\rho(v, i) - \rho(u, i) < \mathrm{max}\{ \rho(v, i), v \in \nup \} -
%\rho(u, i) \le \varepsilon_p$
%\end{enumerate}
%
%Пусть утверждение выполняется для $|I| = l-1$.
%Покажем, что для $|I|=l$ выполняется
%
%$\frac{1}{l} \cdot \sum \limits_{i=1}^{l} |\rho(u, i) - \rho(v, i)|
%\le \varepsilon_p$\\
%
%Пусть $\rho(u, i) \ge \rho(v, i)$, тогда:\\
%
%$\rho(u, v) = \sum \limits_{i=1}^{l-1} |\rho(u, i) - \rho(v, i)|$ +
%$(\rho(u, i) - \rho(v, i)) <$\\
%
%$\sum \limits_{i=1}^{l-1} |\rho(u, i) - \rho(v, i)|$
%+ $(\rho(u, i) - \mathrm{min}\{ \rho(v, i), v \in \nup \}) <$  \\
%
%$\sum \limits_{i=1}^{l-1}
%|\rho(u, i) - \mathrm{min}\{ \rho(v, i), v \in \nup \}|$
%+ $(\rho(u, i) - \mathrm{min}\{ \rho(v, i), v \in \nup \}) = $  $\rho(u, u^{\bigcup}) \le \varepsilon$
%
%Пусть $\rho(u, i) \ge \rho(v, i)$, тогда:\\
%
%$\rho(u, v) = \sum \limits_{i=1}^{l-1} |\rho(u, i) - \rho(v, i)|$ +
%$(\rho(u, i) - \rho(v, i)) <$\\
%
%$\sum \limits_{i=1}^{l-1} |\rho(u, i) - \rho(v, i)|$
%+ $(\mathrm{max}\{ \rho(v, i), v \in \nup \} - \rho(u, i)) <$  \\
%
%$\sum \limits_{i=1}^{l-1}
%|\rho(u, i) - \mathrm{max}\{ \rho(v, i), v \in \nup \}|$
%+ $(\mathrm{max}\{ \rho(v, i), v \in \nup \} - \rho(u, i)) =
%\rho(u, u^{\bigcap}) \le \varepsilon$.

%\subsection{Результат}
%За счет представления контентов в виде нечетких множеств и введения обощенного
%расстояния Хэмминга между агентами системы, были сформированы нечеткие
%модели КРС: нечеткая ООМ и нечеткая СОМ. В нечетких ООМ и СОМ представлены
%алгоритмы решения, основанные на правилах вывода КРС, которые гарантируют
%выполнение достаточных и необходимых условий получения аккуратного или точного
%решения. Нечеткая КРС является более стабильным представителем КРС
%по критерию получения точного и аккуратного решения.
%При использовании нечеткой КРС с разработчика снимается
%дополнительная нагрузка в выборе меры сходства и порогового параметра так,
%чтобы выполнялись необходимые и достаточные условия.
%Достигнута одна из поставленных целей решения: разработать модель РС, в
%которой, при выполнении эвристических утверждений, будут сняты дополнительные
%ограничения.
%В контентной модели представлен способ определения расстояния расстояния
%между пользователем и объектом за счет введения функции $\dc$. Представленный
%способ определения расстояния и расстояние $\rh$ являются формальной техникой
%решения в контентной модели.
%
%Формальность контентной техники решения заключается в определении
%отображения пользователей на множество объектов. В данном методе нет
%эвристик. Контентная модель и техника решения может быть использована с
%совершенно различными реальными данными и построенными для них РС.
%Разработчикам необходимо лишь определить $\dc$, которая может быть основана
%на эвристиках, или нет. Но при этом, независимо от реализации $\dc$, применении
%контентной модели и техники решения гарантирует, что если $\dc$ задана
%аккуратно (что можно проверить при проведении тестирования, решая задачу
%прогнозирования), то тогда решения задач прогнозирования и $topN$
%будут аккуратны и точны. Такое свойство контентной модели и техники решения
%является и сильной и слабой стороной: с одной стороны это дает
%гибкость разработки и применения:
%разработчики могут подстраивать реализацию $\dc$ и применять модель
%и технику на различных входных данных. С другой стороны разработчикам
%необходимо определить функцию $\dc$, что может являться сложной задачей,
%в отличии от КФ, где уже существует метод решения и разработчикам не нужно
%ничего придумывать, а только реализовать алгоритмы и выбрать
%параметры КФ \ref{params-krt}.
%
%TODO: картинка, где есть моя РС и ей подсовывают $\dc$.
%На основании функции $\rh$ определена оценка $\ec$
%задачи прогнозирования и $topN$, значение которой является объективным
%показателем решения этих задач. Оценка $\ec$ коррелирует с использующимися
%оценками $\eap$ и $\eit$.
%Таким образом, на данном этапе решены следующие поставленные задачи:
%
%\begin{enumerate}
%	\item Разработана формальная техника решения $\Pi$;
%	\item Разработана обобщенная оценка эффективности, коррелирующая с
%		существующими оценками эффективности.
%\end{enumerate}
